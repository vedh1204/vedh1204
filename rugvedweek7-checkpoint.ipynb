{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b45e57-d1a5-4d94-86ea-911dc0a9e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Extract MNIST zip file\n",
    "zip_path = \"mnist.zip\"  # Change this to your actual zip file path\n",
    "extract_path = \"mnist_data\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb078cfd-0d0c-4d0f-9dbc-c0ade6bfd1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['t10k-images-idx3-ubyte', 't10k-images.idx3-ubyte', 't10k-labels-idx1-ubyte', 't10k-labels.idx1-ubyte', 'train-images-idx3-ubyte', 'train-images.idx3-ubyte', 'train-labels-idx1-ubyte', 'train-labels.idx1-ubyte']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the extracted_files directory\n",
    "extracted_files_dir = 'extracted_files'\n",
    "files = os.listdir(extracted_files_dir)\n",
    "print(\"Extracted files:\", files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97016ed1-2c85-407d-ad9f-8f7b422fa2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the zip file:\n",
      "File Name                                             Modified             Size\n",
      "t10k-images.idx3-ubyte                         2025-01-30 09:53:44      8892375\n",
      "t10k-labels.idx1-ubyte                         2025-01-30 09:53:44        10008\n",
      "train-images.idx3-ubyte                        2025-01-30 09:53:44     53261448\n",
      "train-labels.idx1-ubyte                        2025-01-30 09:53:44        60009\n",
      "t10k-images-idx3-ubyte/t10k-images-idx3-ubyte  2025-01-30 09:53:44      8892375\n",
      "t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte  2025-01-30 09:53:44        10008\n",
      "train-images-idx3-ubyte/train-images-idx3-ubyte 2025-01-30 09:53:44     53261448\n",
      "train-labels-idx1-ubyte/train-labels-idx1-ubyte 2025-01-30 09:53:44        60009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile('utf8_encoded_zip_file.zip', 'r') as zip_ref:\n",
    "    # List the contents of the zip file\n",
    "    print(\"Contents of the zip file:\")\n",
    "    zip_ref.printdir()\n",
    "    \n",
    "    # Extract all files\n",
    "    zip_ref.extractall('extracted_utf8_files')\n",
    "    \n",
    "    # Read and print the contents of each file\n",
    "    for file_name in zip_ref.namelist():\n",
    "        with open(f'extracted_utf8_files/{file_name}', 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            print(f\"\\nContents of {file_name}:\\n{content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb0ae9-7bea-4e51-a8fc-de72cebe21ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b9c271-3781-4fab-9ec0-d075317afbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "    # Debugging: Check if files are extracted properly\n",
    "    print(os.listdir('data'))\n",
    "    \n",
    "    X_train = np.loadtxt('data/train_images.txt', delimiter=',')\n",
    "    y_train = np.loadtxt('data/train_labels.txt', delimiter=',').astype(int)\n",
    "    X_test = np.loadtxt('data/test_images.txt', delimiter=',')\n",
    "    y_test = np.loadtxt('data/test_labels.txt', delimiter=',').astype(int)\n",
    "    \n",
    "    # Normalize data (scale to [0, 1])\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    def one_hot_encode(y, num_classes):\n",
    "        return np.eye(num_classes)[y]\n",
    "\n",
    "    y_train = one_hot_encode(y_train, 10)\n",
    "    y_test = one_hot_encode(y_test, 10)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba997524-91b7-4a9e-accb-1a887e303d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec26c953-d8df-453a-9f08-4d13118f465c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train-images.idx3-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load training and testing data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_mnist_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain-images.idx3-ubyte\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m y_train \u001b[38;5;241m=\u001b[39m load_mnist_labels(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain-labels.idx1-ubyte\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m X_test \u001b[38;5;241m=\u001b[39m load_mnist_images(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt10k-images.idx3-ubyte\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mload_mnist_images\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_mnist_images\u001b[39m(filename):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(f\u001b[38;5;241m.\u001b[39mread(), np\u001b[38;5;241m.\u001b[39muint8, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-images.idx3-ubyte'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST data\n",
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1, 28*28)\n",
    "    return data / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data\n",
    "\n",
    "# Load training and testing data\n",
    "X_train = load_mnist_images('train-images.idx3-ubyte')\n",
    "y_train = load_mnist_labels('train-labels.idx1-ubyte')\n",
    "X_test = load_mnist_images('t10k-images.idx3-ubyte')\n",
    "y_test = load_mnist_labels('t10k-labels.idx1-ubyte')\n",
    "\n",
    "# One-hot encode labels\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "y_train = one_hot_encode(y_train)\n",
    "y_test = one_hot_encode(y_test)\n",
    "\n",
    "# Neural network parameters\n",
    "input_size = 784  # 28x28\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "# Initialize weights and biases\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Activation functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    Z1 = np.dot(X_train, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = -np.sum(y_train * np.log(A2)) / y_train.shape[0]\n",
    "    \n",
    "    # Backward propagation\n",
    "    dZ2 = A2 - y_train\n",
    "    dW2 = np.dot(A1.T, dZ2) / y_train.shape[0]\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / y_train.shape[0]\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * (A1 > 0)\n",
    "    dW1 = np.dot(X_train.T, dZ1) / y_train.shape[0]\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / y_train.shape[0]\n",
    "    \n",
    "    # Update weights and biases\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss}')\n",
    "\n",
    "# Evaluation\n",
    "Z1 = np.dot(X_test, W1) + b1\n",
    "A1 = relu(Z1)\n",
    "Z2 = np.dot(A1, W2) + b2\n",
    "A2 = softmax(Z2)\n",
    "\n",
    "predictions = np.argmax(A2, axis=1)\n",
    "accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b32f3-7c4f-40f9-903c-4b410827e56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d064fd0-c62b-4d20-adeb-73afd8f877e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train-images-idx3-ubyte.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Load data and train the network\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 109\u001b[0m     X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# Initialize the neural network\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data\u001b[39m():\n\u001b[1;32m---> 14\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mread_idx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain-images-idx3-ubyte.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m read_idx(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain-labels-idx1-ubyte.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m read_idx(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt10k-images-idx3-ubyte.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36mread_idx\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_idx\u001b[39m(filename):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m         zero, data_type, dims \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>HBB\u001b[39m\u001b[38;5;124m'\u001b[39m, f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      9\u001b[0m         shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>I\u001b[39m\u001b[38;5;124m'\u001b[39m, f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dims))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\gzip.py:62\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     60\u001b[0m gz_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[1;32m---> 62\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     64\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\gzip.py:194\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    192\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-images-idx3-ubyte.gz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import gzip\n",
    "\n",
    "# Function to read IDX files\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data():\n",
    "    X_train = read_idx('train-images-idx3-ubyte.gz')\n",
    "    y_train = read_idx('train-labels-idx1-ubyte.gz')\n",
    "    X_test = read_idx('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = read_idx('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # Normalize data\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    # Flatten images\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    # One-hot encode labels\n",
    "    def one_hot_encode(y, num_classes=10):\n",
    "        return np.eye(num_classes)[y]\n",
    "    \n",
    "    y_train = one_hot_encode(y_train)\n",
    "    y_test = one_hot_encode(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Define the Neural Network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "    \n",
    "    # Activation function (ReLU)\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    # Derivative of ReLU\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    # Softmax function\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Output layer error\n",
    "        self.dz2 = output - y\n",
    "        self.dW2 = np.dot(self.a1.T, self.dz2) / m\n",
    "        self.db2 = np.sum(self.dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Hidden layer error\n",
    "        self.dz1 = np.dot(self.dz2, self.W2.T) * self.relu_derivative(self.a1)\n",
    "        self.dW1 = np.dot(X.T, self.dz1) / m\n",
    "        self.db1 = np.sum(self.dz1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    # Update parameters\n",
    "    def update_parameters(self, learning_rate):\n",
    "        self.W1 -= learning_rate * self.dW1\n",
    "        self.b1 -= learning_rate * self.db1\n",
    "        self.W2 -= learning_rate * self.dW2\n",
    "        self.b2 -= learning_rate * self.db2\n",
    "    \n",
    "    # Train the network\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "            self.update_parameters(learning_rate)\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                loss = -np.sum(y * np.log(output)) / X.shape[0]\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    \n",
    "    # Predict\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "# Load data and train the network\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train, X_test, y_test = load_data()\n",
    "    \n",
    "    # Initialize the neural network\n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_size = 128\n",
    "    output_size = 10\n",
    "    nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Train the network\n",
    "    epochs = 1000\n",
    "    learning_rate = 0.1\n",
    "    nn.train(X_train, y_train, epochs, learning_rate)\n",
    "    \n",
    "    # Test the network\n",
    "    predictions = nn.predict(X_test)\n",
    "    accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c901a8-b5d9-4964-9a85-1da06d7499cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "data/train_images.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 106\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Load data from zip file\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     zip_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist.zip\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your zip file path\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# Initialize the neural network\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36mload_data_from_zip\u001b[1;34m(zip_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load training data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/train_images.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train_labels.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1395\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1393\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1395\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1022\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1022\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1024\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_datasource.py:192\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_datasource.py:529\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    527\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: data/train_images.txt not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Step 1: Load and preprocess data from the zip file\n",
    "def load_data_from_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    \n",
    "    # Load training data\n",
    "    X_train = np.loadtxt('data/train_images.txt', delimiter=',')\n",
    "    y_train = np.loadtxt('data/train_labels.txt', delimiter=',').astype(int)\n",
    "    \n",
    "    # Load test data\n",
    "    X_test = np.loadtxt('data/test_images.txt', delimiter=',')\n",
    "    y_test = np.loadtxt('data/test_labels.txt', delimiter=',').astype(int)\n",
    "    \n",
    "    # Normalize data (scale to [0, 1])\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    # One-hot encode labels\n",
    "    def one_hot_encode(y, num_classes):\n",
    "        return np.eye(num_classes)[y]\n",
    "    \n",
    "    y_train = one_hot_encode(y_train, 10)\n",
    "    y_test = one_hot_encode(y_test, 10)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Step 2: Define the Neural Network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "    \n",
    "    # Activation function (ReLU)\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    # Derivative of ReLU\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    # Softmax function\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Output layer error\n",
    "        self.dz2 = output - y\n",
    "        self.dW2 = np.dot(self.a1.T, self.dz2) / m\n",
    "        self.db2 = np.sum(self.dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Hidden layer error\n",
    "        self.dz1 = np.dot(self.dz2, self.W2.T) * self.relu_derivative(self.a1)\n",
    "        self.dW1 = np.dot(X.T, self.dz1) / m\n",
    "        self.db1 = np.sum(self.dz1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    # Update parameters\n",
    "    def update_parameters(self, learning_rate):\n",
    "        self.W1 -= learning_rate * self.dW1\n",
    "        self.b1 -= learning_rate * self.db1\n",
    "        self.W2 -= learning_rate * self.dW2\n",
    "        self.b2 -= learning_rate * self.db2\n",
    "    \n",
    "    # Train the network\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "            self.update_parameters(learning_rate)\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                loss = -np.sum(y * np.log(output)) / X.shape[0]\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    \n",
    "    # Predict\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "# Step 3: Load data and train the network\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from zip file\n",
    "    zip_path = 'mnist.zip'  # Replace with your zip file path\n",
    "    X_train, y_train, X_test, y_test = load_data_from_zip(zip_path)\n",
    "    \n",
    "    # Initialize the neural network\n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_size = 128\n",
    "    output_size = 10\n",
    "    nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Train the network\n",
    "    epochs = 1000\n",
    "    learning_rate = 0.1\n",
    "    nn.train(X_train, y_train, epochs, learning_rate)\n",
    "    \n",
    "    # Test the network\n",
    "    predictions = nn.predict(X_test)\n",
    "    accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c62f7f4-a49e-408d-9792-66ea04398bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    \n",
    "    # Debugging: Check if files are extracted properly\n",
    "    print(\"Extracted files:\", os.listdir('data'))\n",
    "\n",
    "    # Load training data\n",
    "    X_train = np.loadtxt('data/train_images.txt', delimiter=',')\n",
    "    y_train = np.loadtxt('data/train_labels.txt', delimiter=',').astype(int)\n",
    "    \n",
    "    # Load test data\n",
    "    X_test = np.loadtxt('data/test_images.txt', delimiter=',')\n",
    "    y_test = np.loadtxt('data/test_labels.txt', delimiter=',').astype(int)\n",
    "    \n",
    "    # Normalize data (scale to [0, 1])\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    # One-hot encode labels\n",
    "    def one_hot_encode(y, num_classes):\n",
    "        return np.eye(num_classes)[y]\n",
    "    \n",
    "    y_train = one_hot_encode(y_train, 10)\n",
    "    y_test = one_hot_encode(y_test, 10)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5117ac71-800c-44dc-9871-e549af895be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Step 1: Load and preprocess data from the zip file\n",
    "def load_data_from_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    \n",
    "    # Load training data\n",
    "    X_train = np.loadtxt('data/train_images.txt', delimiter=',')\n",
    "    y_train = np.loadtxt('data/train_labels.txt', delimiter=',').astype(int)\n",
    "    \n",
    "    # Load test data\n",
    "    X_test = np.loadtxt('data/test_images.txt', delimiter=',')\n",
    "    y_test = np.loadtxt('data/test_labels.txt', delimiter=',').astype(int)\n",
    "    \n",
    "    # Normalize data (scale to [0, 1])\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    # One-hot encode labels\n",
    "    def one_hot_encode(y, num_classes):\n",
    "        return np.eye(num_classes)[y]\n",
    "    \n",
    "    y_train = one_hot_encode(y_train, 10)\n",
    "    y_test = one_hot_encode(y_test, 10)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Step 2: Define the Neural Network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "    \n",
    "    # Activation function (ReLU)\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    # Derivative of ReLU\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    # Softmax function\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Output layer error\n",
    "        self.dz2 = output - y\n",
    "        self.dW2 = np.dot(self.a1.T, self.dz2) / m\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfeb7846-b502-4078-bf87-138c9a69ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t10k-images-idx3-ubyte', 't10k-images.idx3-ubyte', 't10k-labels-idx1-ubyte', 't10k-labels.idx1-ubyte', 'train-images-idx3-ubyte', 'train-images.idx3-ubyte', 'train-labels-idx1-ubyte', 'train-labels.idx1-ubyte']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "extracted_files = os.listdir('data')\n",
    "print(extracted_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dad668c-6d1e-4970-a342-2a43e02efceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data/train-images-idx3-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 111\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    110\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvedhr\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmnist (2).zip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 111\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_size\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    113\u001b[0m nn\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 23\u001b[0m, in \u001b[0;36mload_data_from_zip\u001b[1;34m(zip_path)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m labels\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Load training data\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_mnist_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/train-images-idx3-ubyte\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m y_train \u001b[38;5;241m=\u001b[39m load_mnist_labels(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train-labels-idx1-ubyte\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36mload_data_from_zip.<locals>.load_mnist_images\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_mnist_images\u001b[39m(filename):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     12\u001b[0m         magic, num, rows, cols \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(f, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint32, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     13\u001b[0m         images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(f, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mreshape(num, rows \u001b[38;5;241m*\u001b[39m cols)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'data/train-images-idx3-ubyte'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Step 1: Load and preprocess data from the zip file\n",
    "def load_data_from_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    \n",
    "    def load_mnist_images(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            magic, num, rows, cols = np.fromfile(f, dtype=np.uint32, count=4)\n",
    "            images = np.fromfile(f, dtype=np.uint8).reshape(num, rows * cols)\n",
    "            return images\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            magic, num = np.fromfile(f, dtype=np.uint32, count=2)\n",
    "            labels = np.fromfile(f, dtype=np.uint8)\n",
    "            return labels\n",
    "\n",
    "    # Load training data\n",
    "    X_train = load_mnist_images('data/train-images-idx3-ubyte')\n",
    "    y_train = load_mnist_labels('data/train-labels-idx1-ubyte')\n",
    "    \n",
    "    # Load test data\n",
    "    X_test = load_mnist_images('data/t10k-images-idx3-ubyte')\n",
    "    y_test = load_mnist_labels('data/t10k-labels-idx1-ubyte')\n",
    "    \n",
    "    # Normalize data (scale to [0, 1])\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    # One-hot encode labels\n",
    "    def one_hot_encode(y, num_classes):\n",
    "        return np.eye(num_classes)[y]\n",
    "    \n",
    "    y_train = one_hot_encode(y_train, 10)\n",
    "    y_test = one_hot_encode(y_test, 10)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Step 2: Define the Neural Network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "    \n",
    "    # Activation function (ReLU)\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    # Derivative of ReLU\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    # Softmax function\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Output layer error\n",
    "        self.dz2 = output - y\n",
    "        self.dW2 = np.dot(self.a1.T, self.dz2) / m\n",
    "        self.db2 = np.sum(self.dz2, axis=0) / m\n",
    "        \n",
    "        # Hidden layer error\n",
    "        self.dz1 = np.dot(self.dz2, self.W2.T) * self.relu_derivative(self.z1)\n",
    "        self.dW1 = np.dot(X.T, self.dz1) / m\n",
    "        self.db1 = np.sum(self.dz1, axis=0) / m\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.W2 -= self.learning_rate * self.dW2\n",
    "        self.b2 -= self.learning_rate * self.db2\n",
    "        self.W1 -= self.learning_rate * self.dW1\n",
    "        self.b1 -= self.learning_rate * self.db1\n",
    "    \n",
    "    # Train the neural network\n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "    \n",
    "    # Predict function\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "# Example usage\n",
    "zip_path = r'C:\\Users\\vedhr\\Downloads\\mnist (2).zip'\n",
    "X_train, y_train, X_test, y_test = load_data_from_zip(zip_path)\n",
    "nn = NeuralNetwork(input_size=X_train.shape[1], hidden_size=64, output_size=10)\n",
    "nn.train(X_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "predictions = nn.predict(X_test)\n",
    "accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42bddfb-07f4-4394-90d2-048f28c60d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\vedhr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fe22a35-ba0c-4d5a-9a49-ac102a5e4d1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2776062305.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    sudo jupyter notebook\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sudo jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef90ecf-f4d5-4cab-80df-491a83c2e4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
